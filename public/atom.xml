<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    
    <title>Bloggin on Responsible AI</title>
    <description>Bloggin on Responsible AI</description>
    <link>http://localhost:1313/</link>
    <description>Recent content on Bloggin on Responsible AI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Mar 2025 17:27:56 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/atom.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fairness in Social Influence Maximization via Optimal Transport</title>
      <link>http://localhost:1313/posts/fairness-in-social-influence-maximization-via-optimal-transport/</link>
      <pubDate>Sat, 15 Mar 2025 17:27:56 +0100</pubDate>
      <guid>http://localhost:1313/posts/fairness-in-social-influence-maximization-via-optimal-transport/</guid>
      <description>&lt;h3 id=&#34;authors-guillaume-marin-bertin--jaishan-burton-elmo&#34;&gt;Authors: Guillaume MARIN-BERTIN &amp;amp; Jaishan BURTON ELMO&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mutual-fairness&#34;&gt;2. Mutual Fairness: A New Metric&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#why-make-a-new-metric&#34;&gt;2.1 Why Make a New Metric?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#proposed-fairness-metric&#34;&gt;2.2 Proposed Fairness Metric&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#short-example&#34;&gt;2.3 Short Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#fairness-evaluation&#34;&gt;3. Metric in Practice&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mutual-fairness-practice&#34;&gt;3.1 Mutual Fairness in Practice&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#impact-of-beta&#34;&gt;3.2 Impact of β&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#s3d-algorithm&#34;&gt;4. Improving Fairness with S3D&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#stochastic-seed-selection-descent&#34;&gt;4.1 Stochastic Seed Selection Descent (S3D)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experimentation&#34;&gt;4.2 Experimentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#impact-of-s3d&#34;&gt;4.3 Impact of S3D&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;5. Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the article “Fairness in Social Influence Maximization via Optimal Transport” published by Shubham Chowdhary et al. in 2024 and available &lt;a href=&#34;https://neurips.cc/virtual/2024/poster/94521&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Knowledge Distillation:  Boosting Interpretability in Deep Learning Models</title>
      <link>http://localhost:1313/posts/impact-knowledge-distillation-model-interpretability/</link>
      <pubDate>Sat, 15 Mar 2025 12:16:21 +0100</pubDate>
      <guid>http://localhost:1313/posts/impact-knowledge-distillation-model-interpretability/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;   code.has-jax {font:inherit;&#xD;&#xA;                  font-size:100%;&#xD;&#xA;                  background: inherit;&#xD;&#xA;                  border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script TYPE=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;   MathJax.Hub.Config({&#xD;&#xA;      tex2jax: {&#xD;&#xA;         inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\$&#39;,&#39;\$&#39;]],&#xD;&#xA;         skipTags: [&#39;script&#39;,&#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;      }&#xD;&#xA;   });&#xD;&#xA;&#xD;&#xA;   MathJax.Hub.Queue(function() {&#xD;&#xA;      var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;      for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;         all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;      }&#xD;&#xA;   });&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script TYPE=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;fr&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;   &lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;   &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 28px;&#34;&gt;Interpretability, the hidden power of knowledge distillation&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;Published March 15, 2025&lt;/p&gt;&#xD;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;a href=&#34;https://github.com/BryanBradfo/responsible-ai-datascience-ipParis.github.io&#34; class=&#34;btn&#34; style=&#34;text-decoration: none; display: inline-block; padding: 8px 16px; background-color: #f1f1f1; border: 1px solid #ddd; border-radius: 4px; color: black;&#34;&gt;Update on GitHub&lt;/a&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;div style=&#34;display: flex; margin-top: 20px;&#34;&gt;&#xD;&#xA;   &lt;div style=&#34;display: flex; align-items: center; margin-right: 20px;&#34;&gt;&#xD;&#xA;      &lt;img src=&#34;./images/Bryan_Remi/bryan.jpeg&#34; alt=&#34;Bryan Chen&#34; style=&#34;width: 40px; height: 40px; border-radius: 50%; margin-right: 10px;&#34;&gt;&#xD;&#xA;      &lt;div&gt;&#xD;&#xA;         &lt;a href=&#34;https://github.com/BryanBradfo&#34; style=&#34;text-decoration: none; color: #0366d6;&#34;&gt;bryanbradfo&lt;/a&gt;&#xD;&#xA;         &lt;p style=&#34;margin: 0;&#34;&gt;Bryan Chen&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Visual Feature Reliance Through the Lens of Complexity</title>
      <link>http://localhost:1313/posts/understanding_visual_feature_reliance_through_the_lens_of_complexity/</link>
      <pubDate>Wed, 12 Mar 2025 16:28:12 +0100</pubDate>
      <guid>http://localhost:1313/posts/understanding_visual_feature_reliance_through_the_lens_of_complexity/</guid>
      <description>&lt;hr&gt;&lt;/hr&gt;&#xD;&#xA;&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\$&#39;,&#39;\$&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;]&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Understanding Visual Feature Reliance through the Lens of Complexity&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors: DIB Caren, SABA Jean Paul, WANG Romain&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Article: &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2024/file/819977c0a95458911bbfd9e5b5115018-Paper-Conference.pdf&#34;&gt;Understanding Visual Feature Reliance through the Lens of Complexity&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#feature-extraction&#34;&gt;Feature Extraction via Dictionary Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#detecting-complexity&#34;&gt;Detecting Complexity&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#redundancy&#34;&gt;Relations with Redundancy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#robustness&#34;&gt;Relations with Robustness&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#importance&#34;&gt;Importance Measure&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#replication&#34;&gt;Feature Flow and Information Theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experiment&#34;&gt;Experiment Summary: Exploring Feature Complexity in ResNet18&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experiment_1&#34;&gt;How the Code Was Structured and What Was Done&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experiment_2&#34;&gt;Experiment Results and Interpretation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;introduction&#34;&gt;1. Introduction&lt;/h1&gt;&#xA;&lt;p&gt;In this blog, we’ll take a deep dive into an insightful and thought-provoking paper authored by Thomas Fel, Louis Béthune, Andrew Kyle Lampinen, Thomas Serre, and Katherine Hermann. Their work explores the intricate mechanisms underlying how deep neural networks—specifically ResNet50—learn and represent complex features. This research, rooted in both theoretical and empirical analysis, investigates the nature of feature complexity, how features evolve over the course of training, and the computational structures that enable neural networks to generalize effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Get a calibrated and efficient model with tailored data augmentation.</title>
      <link>http://localhost:1313/posts/mixupdatacalibration/</link>
      <pubDate>Sun, 09 Mar 2025 21:03:13 +0100</pubDate>
      <guid>http://localhost:1313/posts/mixupdatacalibration/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h2 id=&#34;authors--tristan-waddington-fabien-lagnieu--dimitri-henrard-iratchet&#34;&gt;Authors : &lt;em&gt;Tristan Waddington, Fabien Lagnieu &amp;amp; Dimitri Henrard-Iratchet&lt;/em&gt;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;comment-on-the-research-paper-tailoring-mixup-to-data-for-calibrationhttpsarxivorgabs231101434-written-by-quentin-bouniot-pavlo-mozharovskyi--florence-dalché-buc-from-ltci-télécom-paris-institut-polytechnique-de-paris-france&#34;&gt;Comment on the research paper: &lt;a href=&#34;https://arxiv.org/abs/2311.01434&#34;&gt;&lt;strong&gt;Tailoring Mixup to Data for Calibration&lt;/strong&gt;&lt;/a&gt;, written by &lt;em&gt;Quentin Bouniot, Pavlo Mozharovskyi &amp;amp; Florence d’Alché-Buc&lt;/em&gt;, from LTCI, Télécom Paris, Institut Polytechnique de Paris, France&lt;/h2&gt;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#1-existing-data-augmentation-methods&#34;&gt;Existing Data Augmentation Methods&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#2-understanding-calibration&#34;&gt;Understanding Calibration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#3-best-of-both-worlds-tailoring-mixup-to-data-for-calibration&#34;&gt;Best of both worlds: Tailoring Mixup to Data for Calibration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&amp;ldquo;But it works well on the training set!&amp;rdquo; is the machine learning equivalent to the classic &amp;ldquo;But it works on my computer!&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>BitFit: BIas-Term FIne-Tuning</title>
      <link>http://localhost:1313/posts/bitfit/</link>
      <pubDate>Wed, 19 Feb 2025 15:20:48 +0100</pubDate>
      <guid>http://localhost:1313/posts/bitfit/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;BitFit: A Simpler and More Efficient Approach to Fine-tuning Transformers&lt;/h1&gt;&#xD;&#xA;&lt;h3 id=&#34;authors--abdoul-r-zeba-nour-yahya-nourelhouda-klich&#34;&gt;Authors : Abdoul R. Zeba, Nour Yahya, Nourelhouda Klich&lt;/h3&gt;&#xA;&lt;h2 style=&#34;font-size: 20px;&#34;&gt; 1. Introduction &lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Fine-tuning large transformer models like BERT has become the gold standard for adapting them to specific tasks. However, this process is often computationally expensive, requiring vast amounts of memory, making it impractical for many real-world applications. What if there was a way to adapt these models with minimal computational overhead while maintaining competitive performance?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Axiomatic Explanations for Visual Search, Retrieval and Similarity Learning</title>
      <link>http://localhost:1313/posts/axiomatic_explanations/</link>
      <pubDate>Thu, 28 Mar 2024 05:58:39 +0100</pubDate>
      <guid>http://localhost:1313/posts/axiomatic_explanations/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;en&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;&lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;title&gt;Styled Table&lt;/title&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;    table {&#xD;&#xA;        border-collapse: collapse;&#xD;&#xA;        width: 100%;&#xD;&#xA;    }&#xD;&#xA;    th, td {&#xD;&#xA;        padding: 8px;&#xD;&#xA;        text-align: center;&#xD;&#xA;        border-bottom: 1px solid #ddd;&#xD;&#xA;    }&#xD;&#xA;    th {&#xD;&#xA;        background-color: #f2f2f2;&#xD;&#xA;    }&#xD;&#xA;    tr:hover {&#xD;&#xA;        background-color: #f5f5f5;&#xD;&#xA;    }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;/html&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;AXIOMATIC EXPlanATIONS FOR VISUAL SEARCh, RETRIEVAL, AND SIMILARITY LEARNING &lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 13px;&#34;&gt;Authors:Mark Hamilton ${ }^{1,2}$, Scott Lundberg ${ }^{2}$, Stephanie Fu ${ }^{1}$, Lei Zhang ${ }^{2}$, William T. Freeman ${ }^{1,3}$&lt;br&gt;${ }^{1}$ MIT, ${ }^{2}$ Microsoft, ${ }^{3}$ Google&lt;br&gt;markth@mit.edu&#xD;&#xA;&lt;br/&gt;&#xD;&#xA;**Authors of the blogpost**: Yassine Beniguemim and Noureddine BOULLAM.&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Exploring Visual Search Algorithm Explanations&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.1&#34;&gt;First-Order Explanations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.2&#34;&gt;Unifying First-Order Search Interpretation Techniques&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.3&#34;&gt;Second-Order Explanations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.4&#34;&gt;A Fast Shapley-Taylor Approximation Kernel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.5&#34;&gt;Second-Order Search Activation Maps&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Implementing Second-Order Explanations in Practice&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0.0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Visual search, recommendation, and contrastive similarity learning are pivotal technologies shaping user experiences in the digital age. However, the complexity of modern model architectures often obscures their inner workings, making them challenging to interpret. In our blog, we delve into a groundbreaking paper titled &amp;ldquo;AXIOMATIC EXPLANATIONS FOR VISUAL SEARCH, RETRIEVAL, AND SIMILARITY LEARNING&amp;rdquo; authored by Mark Hamilton et al. This paper introduces a novel framework grounded in the theory of fair credit assignment, providing axiomatic solutions that generalize existing explanation techniques and address fairness concerns in recommendation systems. Through our exploration, we aim to demystify the complexities of visual search algorithms, offering readers insights into their operation and implications for various domains.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Privacy Amplification by Decentralization</title>
      <link>http://localhost:1313/posts/privacy-amplification/</link>
      <pubDate>Wed, 27 Mar 2024 12:05:50 +0100</pubDate>
      <guid>http://localhost:1313/posts/privacy-amplification/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Privacy Amplification by Decentralization&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Sarah ABBANA BENNANI &lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction - the challenge of data privacy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Theoretical Aspects on Differential Privacy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;First Case: walk on a ring&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Generalisation: walk on a complete graph&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Perspectives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br /&gt;&#xD;&#xA;&lt;p&gt;This is a blogpost about the paper  Privacy Amplification by Decentralization, published by E. Cyffers et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v151/cyffers22a/cyffers22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Introduction - the challenge of data privacy&lt;/h1&gt;&lt;/h1&gt;&#xA;&lt;p&gt;In recent years, the concept of privacy has gained significant attention due to the proliferation of data collection practices and the need to safeguard individuals&amp;rsquo; personal information. &lt;br&gt;&#xA;There has been a notable shift towards implementing regulations to govern the gathering of data from individuals, underscoring the pressing demand for privacy measures that are not only effective and robust against potential attacks but also transparent and firmly grounded in logic and mathematics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robust or Fair</title>
      <link>http://localhost:1313/posts/robust-or-fair/</link>
      <pubDate>Wed, 27 Mar 2024 11:37:03 +0100</pubDate>
      <guid>http://localhost:1313/posts/robust-or-fair/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;To be Robust or to be Fair: Towards Fairness in Adversarial Training&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Authors: Maryem Hajji &amp; Cément Teulier&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Initial Analysis&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2.1&#34;&gt;Previous Studies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2.2&#34;&gt;Theoretical Demonstration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Model&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3.1&#34;&gt;Fairness Requirements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3.2&#34;&gt;Practical Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experimentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;This blog post retraces the study conducted in the &lt;a href=&#34;http://proceedings.mlr.press/v139/xu21b.html&#34;&gt;paper&lt;/a&gt; &amp;ldquo;To be Robust or to be Fair: Towards Fairness in Adversarial Training&amp;rdquo; and written by Han Xu, Xiaorui Liu, Yaxin Li, Yaxin Li, Anil K. Jain and Jiliang Tang.&lt;/p&gt;</description>
    </item>
    <item>
      <title>XCM, an explainable CNN for MTS classficiation</title>
      <link>http://localhost:1313/posts/xcm/</link>
      <pubDate>Tue, 26 Mar 2024 00:55:40 +0100</pubDate>
      <guid>http://localhost:1313/posts/xcm/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification&lt;/h1&gt;&#xD;&#xA;&lt;h3 style=&#34;font-size: 24px;&#34;&gt;Authors : Nicolas SAINT &amp; Matthis Guérin&lt;/h3&gt;&#xD;&#xA;&lt;h4 style=&#34;font-size: 22px;&#34;&gt;Table of Contents&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#2-related-work&#34;&gt;2. Related Work&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#3-xcm&#34;&gt;3. XCM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#4-evaluation&#34;&gt;4. Evaluation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#5-results&#34;&gt;5. Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#6-implementation&#34;&gt;6. Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#7-conclusion&#34;&gt;7. Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the article &amp;ldquo;XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification&amp;rdquo; published by Kevin Fauvel et al. in 2021 and available &lt;a href=&#34;https://www.mdpi.com/2227-7390/9/23/3137&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RobustAI_RegMixup</title>
      <link>http://localhost:1313/posts/robustai_regmixup/</link>
      <pubDate>Sun, 24 Mar 2024 12:38:16 +0100</pubDate>
      <guid>http://localhost:1313/posts/robustai_regmixup/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;en&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;&lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;title&gt;Styled Table&lt;/title&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;    table {&#xD;&#xA;        border-collapse: collapse;&#xD;&#xA;        width: 100%;&#xD;&#xA;    }&#xD;&#xA;    th, td {&#xD;&#xA;        padding: 8px;&#xD;&#xA;        text-align: center;&#xD;&#xA;        border-bottom: 1px solid #ddd;&#xD;&#xA;    }&#xD;&#xA;    th {&#xD;&#xA;        background-color: #f2f2f2;&#xD;&#xA;    }&#xD;&#xA;    tr:hover {&#xD;&#xA;        background-color: #f5f5f5;&#xD;&#xA;    }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;/html&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;RegMixup : Regularizer for robust AI&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Improve accuracy and Out-of-Distribution Robustness&lt;h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: Marius Ortega, Ly An CHHAY &lt;br /&gt;&#xD;&#xA;Paper : &lt;a href=&#34;https://arxiv.org/abs/2206.14502&#34;&gt;RegMixup&lt;/a&gt;  by Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Prerequisites&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.1&#34;&gt;Empirical Risk Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.2&#34;&gt;Vicinal Risk Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.3&#34;&gt;Mixup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;RegMixup in theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;RegMixup in practice &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0.0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;In this blog post, we will present the paper &amp;ldquo;RegMixup: Regularizer for robust AI&amp;rdquo; by Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania. This paper introduces a new regularizer called RegMixup, which is designed to improve the accuracy and out-of-distribution robustness of deep neural networks. The authors show that RegMixup can be used to improve the performance of state-of-the-art models on various datasets, including CIFAR-10, CIFAR-100, and ImageNet. The paper also provides an extensive empirical evaluation of RegMixup, demonstrating its effectiveness in improving the robustness of deep neural networks to out-of-distribution samples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints</title>
      <link>http://localhost:1313/posts/lambert-davy/</link>
      <pubDate>Sat, 23 Mar 2024 19:39:13 +0100</pubDate>
      <guid>http://localhost:1313/posts/lambert-davy/</guid>
      <description>&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: Godefroy LAMBERT and Louise DAVY&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Definitions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;AUC-based fairness constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;ROC-based fairness constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints, published by R. Vogel et al. in 2021 and available &lt;a href=&#34;http://proceedings.mlr.press/v130/vogel21a/vogel21a-supp.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 24px; text-decoration: underline;&#34;&gt;Introduction&lt;/h1&gt;&lt;/h1&gt;&#xA;&lt;p&gt;With recent advances in machine learning, applications are becoming increasingly numerous and the expectations are high. Those applications will only be able to be deployed if some important issues are addressed such as bias. There are famous datasets known for containing variables that induce a lot of bias such as Compas with racial bias and gender bias in the Adult dataset. To avoid those biases, new algorithms were created to provide more fairness in the prediction by using diverse methods.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Label-Free Explainability</title>
      <link>http://localhost:1313/posts/label-free-explainability/</link>
      <pubDate>Sun, 17 Mar 2024 15:31:34 +0100</pubDate>
      <guid>http://localhost:1313/posts/label-free-explainability/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Label-Free Explainability for Unsupervised Models&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: &lt;a href=&#34;https://github.com/Valentinahxu&#34;&gt;Valentina Hu &lt;/a&gt; and  &lt;a href=&#34;https://github.com/selmazrg&#34;&gt; Selma Zarga&lt;/a&gt;&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Incentives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Feature Importance &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Example Importance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Label-Free Explainability for Unsupervised Models, published by J. Crabbé et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v162/crabbe22a/crabbe22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Why do we need explainability ?&lt;/h2&gt;&#xA;&lt;p&gt;Machine learning models are becoming increasingly capable of making advanced predictions. While models like linear regression are relatively easy to understand and explain, more complex models, often called &lt;strong&gt;&amp;ldquo;black boxes&amp;rdquo;&lt;/strong&gt; due to their complexity, present challenges in explaining how they make predictions. These models can be problematic in highstakes applications such as healthcare, finance, and justice, where it&amp;rsquo;s crucial to justify decision-making. Additionally, in case of errors, it&amp;rsquo;s important to understand the origin in order to address and correct them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adversarially Reweighted Learning</title>
      <link>http://localhost:1313/posts/adversarially_reweighted_learning/</link>
      <pubDate>Mon, 04 Mar 2024 18:35:12 +0100</pubDate>
      <guid>http://localhost:1313/posts/adversarially_reweighted_learning/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Fairness without Demographics through Adversarially Reweighted Learning&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Authors: Pierre Fihey &amp; Guerlain Messin&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Fairness issues in ML and AI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;The privacy of demographic’s data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;The Adversarial Reweighted Learning Model&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;An Hypothesis: Protected Groups are Correlated with Both Features and Labels&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Computational identifiability of protected groups&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;The Rawlsian Max-Min Fairness principle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;The ARL objective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;The Model Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-8&#34;&gt;Results analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-9&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Fairness without Demographics through Adversarially Reweighted Learning, published by P. Lahoti et al. in 2020 and available &lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/3495724.3495786&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Packed Ensembles</title>
      <link>http://localhost:1313/posts/packed-ensembles/</link>
      <description>&lt;script
type=&#34;text/x-mathjax-config&#34;&gt;

MathJax.Hub.Config({

    tex2jax: {

        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],

        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry

    }

});

MathJax.Hub.Queue(function() {

    var all = MathJax.Hub.getAllJax(), i;

    for(i = 0; i &lt; all.length; i += 1) {

        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;

    }

});

&lt;/script&gt;
&lt;script
type=&#34;text/javascript&#34;
src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
This is a blog post about the paper Packed-Ensembles for Efficient Uncertainty Estimation, published by O. Laurent et al. in 2023 and available [here](https://openreview.net/pdf?id=XXTyv1zD9zD).
&lt;h3 id=&#34;authors-cynthia-obeid-and-elie-nakad&#34;&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Cynthia Obeid and Elie Nakad&lt;/h3&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;/div&gt;
The document &#34;Packed-Ensembles for Efficient Uncertainty Estimation&#34; introduces a novel framework for designing and training compact, structured ensembles of neural networks, termed Packed-Ensembles (PE). It addresses the limitations of Deep Ensembles (DE) in terms of computational efficiency and hardware constraints by leveraging grouped convolutions. This technique allows for parallelizing the ensemble into a single shared backbone, improving training and inference speeds within the memory limits of standard neural networks. The paper demonstrates through extensive experiments that PEs maintain the beneficial properties of DEs, such as diversity and robustness to distribution shift, while achieving comparable accuracy, calibration, and out-of-distribution detection capabilities. The work includes implementation details, experimental results on CIFAR-10/100 and ImageNet datasets and comparisons with existing approaches. It concludes with insights on the reproducibility of results and the potential ethical considerations of deploying such models in safety-critical systems.
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Presentation of the model&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Packed-Ensembles&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/fig1.jpg&#34; alt=&#34;The base network and Packed-Ensembles&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;The base network and Packed-Ensembles&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Packed-Ensembles (PE) is a technique for designing and training lightweight ensembles of neural networks. It is based on the idea of using grouped convolutions to create multiple subnetworks within a single network. These subnetworks are trained independently, which helps to improve the efficiency of the ensemble.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Benefits of Packed-Ensembles&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Packed-Ensembles offer several benefits over traditional ensemble methods, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Efficiency:&lt;/strong&gt; Packed-Ensembles are more efficient than traditional ensembles in terms of memory usage and training time. This is because they use grouped convolutions to share parameters between the subnetworks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accuracy:&lt;/strong&gt; Packed-Ensembles can achieve accuracy levels that are comparable to traditional ensembles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Calibration:&lt;/strong&gt; Packed-Ensembles are well-calibrated, meaning that their predicted probabilities are accurate reflections of the true probabilities.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Out-of-distribution (OOD) detection:&lt;/strong&gt; Packed-Ensembles are good at detecting out-of-distribution data, which is data that comes from a different distribution than the data that the model was trained on.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Comparison to other ensemble methods&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The paper compares Packed-Ensembles to several other ensemble methods, including Deep Ensembles, BatchEnsemble, MIMO, and Masksembles. The paper found that Packed-Ensembles are more efficient than all of these methods, and they achieve comparable accuracy on most tasks.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Packed-Ensembles: A Technique for Efficient Neural Network Ensembles&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;Packed-Ensembles (PE) is a method for designing and training lightweight ensembles of neural networks. It aims to improve efficiency while maintaining accuracy and other desirable properties. This technique achieves this by leveraging grouped convolutions to create multiple subnetworks within a single network, enabling them to be trained independently.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Understanding Convolutional Layers and Grouped Convolutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Convolutional Layers:&lt;/strong&gt; These are the backbone of Convolutional Neural Networks (CNNs), performing filtering operations on input data using learnable filters (kernels). Mathematically, the output of a convolutional layer, denoted by $z_{j+1}$, is calculated as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$z^{(j+1)}(c,:,:) = (h^j \otimes \omega^j)(c,:,:) = \sum_{k=0}^{C_{j}-1} \omega^j(c, k,:,:) \star h^j(k,:,:)$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$c$&lt;/strong&gt; represents the channel index&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$h^j$&lt;/strong&gt; denotes the input feature map&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$ω^j$&lt;/strong&gt; represents the weight tensor (kernel)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$⋆$&lt;/strong&gt; denotes the 2D cross-correlation operator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Grouped Convolutions:&lt;/strong&gt; This technique allows training multiple subnetworks within a single network by dividing the channels of feature maps and weight tensors into groups. Each group is processed by a separate set of filters, essentially creating &lt;strong&gt;independent subnetworks&lt;/strong&gt;. The mathematical formulation for grouped convolutions is given by:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
z^{(j+1)}(c,:,:) = \left( h^j \otimes \omega^j_{\gamma} \right) (c,:,:) = \sum_{k=0}^{\frac{C_{j}}{\gamma}-1} \omega^j_{\gamma} (c, k,:,:) \star h^j \left( k + \left\lfloor \frac{c}{C_{j+1}/\gamma} \right\rfloor \frac{C_{j}}{\gamma}, :,:\right)
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;$γ$&lt;/strong&gt; represents the number of groups&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$C_{j+1}$&lt;/strong&gt; and &lt;strong&gt;$C_j$&lt;/strong&gt; denote the number of output and input channels, respectively.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The formula states that a grouped convolution layer is mathematically equivalent to a standard convolution where the weights are selectively applied using a binary mask &lt;strong&gt;$\text{mask}_{m}^j$&lt;/strong&gt;
&lt;strong&gt;$\in \{{ 0, 1 \}}^{C_{j+1} \times C_j \times s_j^2}$&lt;/strong&gt; with $s_j^2$ the kernel size squared of the layer $j$. Each element in $\text{mask}_{m}^j$ is either 0 or 1.&lt;/p&gt;
&lt;p&gt;The condition &lt;strong&gt;$\text{mask}_{m}^j(k, l, :, :) = 1$&lt;/strong&gt; happens only if $\left\lfloor \frac{l}{C_{j}/\gamma} \right\rfloor = \left\lfloor \frac{k}{C_{j+1}/\gamma} \right\rfloor$ for each group $m \in [|0, \gamma - 1 |]$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Complete Mask and Convolution:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;$\text{mask}^j = \sum_{m=0}^{{\gamma}-1}\text{mask}_{m}^j$ : This combines the masks for all groups ($m$) into a single $\text{mask}^j$ for layer $j$.&lt;/li&gt;
&lt;li&gt;$z^{j+1} = h^j \otimes (ω^j ◦ \text{mask}^j)$: This rewrites the grouped convolution operation. Here:
&lt;ul&gt;
&lt;li&gt;$z^{j+1}$: Output feature map of the layer.&lt;/li&gt;
&lt;li&gt;$h^j$: Input feature map.&lt;/li&gt;
&lt;li&gt;$ω^j$: Convolution weights for layer &lt;code&gt;j&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;$\otimes$: Denotes convolution operation.&lt;/li&gt;
&lt;li&gt;$◦$: Denotes Hadamard product (element-wise multiplication).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;In simpler terms:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Grouped convolution divides the input channels and weights into groups.&lt;/li&gt;
&lt;li&gt;A separate mask is created for each group, ensuring elements within a group are aligned.&lt;/li&gt;
&lt;li&gt;These masks effectively turn specific weights to zero during the convolution, essentially selecting which weights contribute to the output for each group.&lt;/li&gt;
&lt;li&gt;The final convolution is equivalent to applying the original weights element-wise multiplied by the combined mask.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Background on Deep Ensembles&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;This section delves into Deep Ensembles (DE), a technique for image classification tasks.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/fig2.png&#34; alt=&#34;Deep Ensembles&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;Deep Ensembles&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting the Scene&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We have a dataset $D$ containing pairs of images and their corresponding labels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x_i$: Represents an image sample with dimensions $C0 \times H0 \times W0$ (likely referring to color channels, height, and width).&lt;/li&gt;
&lt;li&gt;$y_i$ : One-hot encoded label representing the class of the image ($NC$ total classes).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The dataset is assumed to be drawn from a joint distribution $P(X, Y)$.&lt;/p&gt;
&lt;p&gt;A neural network $f_\theta$ processes the images and predicts their class labels. This network has learnable parameters denoted by $\theta$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\hat{y}_i = f_θ(xi)$: The predicted class label for image $x_i$ based on the network with parameters $θ$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Traditional Approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The model predicts probabilities for each class using a Multinoulli distribution. These probabilities are treated as point estimates, meaning they represent the most likely class without considering uncertainty.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introducing Deep Ensembles&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;DE works by training multiple Deep Neural Networks (DNNs) $M$ with random initializations. These DNNs are denoted by $θ_m$ for the $m-th$ network ($0$ to $M-1$).&lt;/p&gt;
&lt;p&gt;The ensemble prediction is obtained by averaging the predictions of all $M$ DNNs as shown in the equation below:&lt;/p&gt;
&lt;p&gt;$$
P(y_i|x_i, D) = M^{-1} \sum_{m=0}^{M-1} P(y_i|x_i, \theta_m)
$$&lt;/p&gt;
&lt;p&gt;This essentially combines the outputs of multiple networks to create a more robust prediction.&lt;/p&gt;
&lt;p&gt;In simpler terms, DE trains multiple neural networks with slight variations and combines their predictions to get a more reliable estimate, including the level of uncertainty in the prediction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Building Packed-Ensembles:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Packed-Ensembles combine the concepts of Deep Ensembles (ensembles of multiple independent DNNs) and grouped convolutions. Here&amp;rsquo;s how it works:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Subnetworks:&lt;/strong&gt; The ensemble is formed by creating &lt;strong&gt;$M$&lt;/strong&gt; smaller subnetworks within the main network architecture. These subnetworks share the same structure but have &lt;strong&gt;independent parameters&lt;/strong&gt; due to the use of grouped convolutions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hyperparameters:&lt;/strong&gt; Packed-Ensembles are defined by three hyperparameters:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;$α$ (alpha):&lt;/strong&gt; expansion factor that scales the width of each subnetwork (compensates for the decrease in capacity due to using fewer parameters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$M$:&lt;/strong&gt; number of subnetworks in the ensemble (represents the ensemble size).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$γ$ (gamma):&lt;/strong&gt; number of groups for grouped convolutions within each subnetwork (introduces another level of sparsity).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mathematical Implementation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The output of a Packed-Ensemble layer is calculated by averaging the predictions from each subnetwork, as shown in the following equation:&lt;/p&gt;
&lt;p&gt;$$
\hat{y} = M^{-1} \sum_{m=0}^{M-1} P(y|\theta_a^m, x) \quad \text{with} \quad \theta_a^m = ({\omega_j^{\alpha} \circ \text{mask}_{m}^j})_j
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;$\hat{y}$&lt;/strong&gt; represents the ensemble&amp;rsquo;s predicted label&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$P(y|θ_a^m, x)$&lt;/strong&gt; denotes the probability of class &lt;strong&gt;$y$&lt;/strong&gt; given the input &lt;strong&gt;$x$&lt;/strong&gt; and the parameters &lt;strong&gt;$θ_a^m$&lt;/strong&gt; of the &lt;strong&gt;$m-th$&lt;/strong&gt; subnetwork&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;$\theta_a^m = ({\omega_j^{\alpha} \circ \text{mask}_{m}^j})_j$&lt;/strong&gt; represents the parameters of the &lt;strong&gt;$m-th$&lt;/strong&gt; subnetwork, obtained by applying element-wise multiplication (&lt;strong&gt;$∘$&lt;/strong&gt;) between the expanded weights (&lt;strong&gt;$\omega_j^{\alpha}$&lt;/strong&gt;) and the group mask (&lt;strong&gt;$\text{mask}_{m}$&lt;/strong&gt;) for each layer &lt;strong&gt;$j$&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Implementation&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/fig4.png&#34; alt=&#34;Equivalent architectures for Packed-Ensembles&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;Equivalent architectures for Packed-Ensembles&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;The authors proposed a method for designing efficient ensemble convolutional layers using grouped convolutions. This approach exploits the parallelization capabilities of GPUs to accelerate training and inference. The sequential training architecture is replaced with parallel implementations, as shown in the part b and c of the figure above. This figure summarizes equivalent architectures for a simple ensemble of M=3 neural networks with three convolutional layers and a final dense layer. In these implementations, feature maps are stacked on the channel dimension (denoted as rearrange operation). This results in a feature map of size M × Cj × Hj × Wj, regrouped by batches of size B × M, where B is the batch size of the ensemble. To maintain the original batch size, the batch is repeated M times after rearrangement. Grouped convolutions with M groups and γ subgroups per subnetwork are employed. Each feature map is processed independently by each subnetwork, resulting in separate outputs. Grouped convolutions are used throughout to ensure gradients remain independent between subnetworks. Other operations, like Batch Normalization, can be applied if they are groupable or act independently on each channel. The figure below illustrates the masks used to encode Packed Ensembles for M=2 and M=2 with γ=2. Finally, implementations (b) and (c) of the figure above are equivalent. A standard convolution can replace the initial steps (rearrangement and first grouped convolution) if all subnetworks receive the same images simultaneously.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/fig5.png&#34; alt=&#34;subnetwork mask&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;Diagram representation of a subnetwork mask: maskj, with M = 2, j an integer corresponding to a fully connected layer&lt;/i&gt;&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Experiments&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;The experiment section evaluates the Packed-Ensembles (PE) method on classification tasks. Here are the key points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Datasets:&lt;/strong&gt; CIFAR-10, CIFAR-100, and ImageNet are used for various complexity levels.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Architectures:&lt;/strong&gt; PE is compared on ResNet-18, ResNet-50, Wide ResNet-28-10 against Deep Ensembles, BatchEnsemble, MIMO, and Masksembles.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Metrics:&lt;/strong&gt; Accuracy (%), Negative Log-Likelihood (NLL), Expected Calibration Error (ECE) for calibration, and Areas Under Precision-Recall (AUPR) and ROC (AUC) curves for Out-of-Distribution (OOD) detection are used.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implementation Details:&lt;/strong&gt; Softmax probabilities from all subnetworks are averaged for prediction. Maximum value of the output vector is considered the class. SVHN dataset is used for OOD detection on CIFAR-10/100. Mutual Information (MI) is used as a criterion for ensemble techniques on ImageNet-O and Texture datasets. ImageNet-R is used to evaluate robustness under distribution shift.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Code:&lt;/strong&gt; PyTorch-Lightning framework is used for implementation.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;The experiment results show that Packed-Ensembles (PE) achieves similar performance to Deep Ensembles (DE) on classification tasks, but with lower memory usage. Here are the key findings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CIFAR-10/100:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;PE performs similarly or slightly better than DE on OOD detection and classification (especially with larger architectures like ResNet-50 and Wide ResNet).&lt;/li&gt;
&lt;li&gt;Smaller architectures (ResNet-18) might not have enough capacity for PE to perform as well on CIFAR-100.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ImageNet:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;PE improves uncertainty quantification for OOD detection and distribution shift compared to DE and single models.&lt;/li&gt;
&lt;li&gt;PE achieves better accuracy with a reasonable increase in training and inference cost.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These results suggest that PE is a memory-efficient alternative to DE for tasks requiring good uncertainty estimation.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/fig3.png&#34; alt=&#34;ResNet50 performance&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;Packed-Ensembles of ResNet50 performance on CIFAR-10 and CIFAR-100&lt;/i&gt;&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Ethics&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;This section emphasizes the ethical considerations of the research. Here are the key points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Goal:&lt;/strong&gt; This research proposes a method to improve uncertainty estimation in deep learning models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limitations:&lt;/strong&gt; The authors acknowledge limitations, particularly for safety-critical systems (systems where failure can have severe consequences). Even though the method aims to improve reliability, it&amp;rsquo;s not ready for such applications.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concerns:&lt;/strong&gt; The text mentions limitations explored in the experiments. These limitations highlight the need for further validation and verification before real-world use, especially concerning robustness in various scenarios like:
&lt;ul&gt;
&lt;li&gt;Unknown situations&lt;/li&gt;
&lt;li&gt;Corner cases (uncommon but important situations)&lt;/li&gt;
&lt;li&gt;Adversarial attacks (attempts to intentionally mislead the model)&lt;/li&gt;
&lt;li&gt;Potential biases in the model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Overall:&lt;/strong&gt; The authors advocate for responsible use of the method and emphasize the importance of further research before deploying it in safety-critical systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;h1&gt;Reproducibility: Packed-Ensemble on CIFAR-10&lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;We attempted to reproduce the experiment outlined in the tutorial available at &lt;a href=&#34;https://torch-uncertainty.github.io/auto_tutorials/tutorial_pe_cifar10.html&#34;&gt;https://torch-uncertainty.github.io/auto_tutorials/tutorial_pe_cifar10.html&lt;/a&gt; which trains a Packed-Ensemble classifier on the CIFAR-10 dataset. The tutorial details a step-by-step approach, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Data Loading and Preprocessing:&lt;/strong&gt; Utilizing torchvision to load the CIFAR-10 dataset and performing normalization on the images.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Packed-Ensemble Definition:&lt;/strong&gt; Defining a Packed-Ensemble model with M=4 subnetworks, alpha=2, and gamma=1, built upon a standard convolutional neural network architecture.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss Function and Optimizer:&lt;/strong&gt; Employing Classification Cross-Entropy loss and SGD with momentum for optimization during training.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Training:&lt;/strong&gt; Training the Packed-Ensemble model on the CIFAR-10 training data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Testing and Evaluation:&lt;/strong&gt; Evaluating the trained Packed-Ensemble on the CIFAR-10 test data, with a focus on uncertainty quantification and OOD (Out-of-Distribution) detection performance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Experimental Runs and Observations:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Test 1:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/Result1.png&#34; alt=&#34;First result&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;GroundTruth:  cat   ship  ship  plane&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;The predicted labels are: cat   ship  ship  ship&lt;/p&gt;
&lt;p&gt;Test 2:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/Result2.png&#34; alt=&#34;Second result&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;GroundTruth: dog bird horse bird&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;The predicted labels are: dog  frog  car  dog&lt;/p&gt;
&lt;p&gt;Test 3:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;./images/Result3.png&#34; alt=&#34;Third result&#34; style=&#34;display:block; margin:auto;&#34;&gt;
&lt;/div&gt;
&lt;p style=&#34;text-align:center;&#34;&gt;&lt;i&gt;GroundTruth:  dog truck plane car &lt;/i&gt;&lt;/p&gt;
&lt;p&gt;The predicted labels are: dog  horse ship  truck&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Challenges and Limitations:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A significant limitation of the tutorial is the lack of guidance on evaluating the model&amp;rsquo;s performance. Without a defined evaluation metric (e.g., accuracy, precision, recall), it&amp;rsquo;s challenging to determine the overall effectiveness of the trained Packed-Ensemble. While the provided test results show inconsistencies between ground truth labels and predictions, a quantitative evaluation metric is necessary to draw more concrete conclusions.&lt;/p&gt;
</description>
      <author>Students from M2 Data Science IP Paris</author>
      <guid>http://localhost:1313/posts/packed-ensembles/</guid>
      <description>&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;div style=&#34;text-align:center;&#34;&gt;&#xD;&#xA;This is a blog post about the paper Packed-Ensembles for Efficient Uncertainty Estimation, published by O. Laurent et al. in 2023 and available [here](https://openreview.net/pdf?id=XXTyv1zD9zD).&#xD;&#xA;&lt;h3 id=&#34;authors-cynthia-obeid-and-elie-nakad&#34;&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Cynthia Obeid and Elie Nakad&lt;/h3&gt;&#xA;&lt;h1&gt;Introduction&lt;/h1&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;The document &#34;Packed-Ensembles for Efficient Uncertainty Estimation&#34; introduces a novel framework for designing and training compact, structured ensembles of neural networks, termed Packed-Ensembles (PE). It addresses the limitations of Deep Ensembles (DE) in terms of computational efficiency and hardware constraints by leveraging grouped convolutions. This technique allows for parallelizing the ensemble into a single shared backbone, improving training and inference speeds within the memory limits of standard neural networks. The paper demonstrates through extensive experiments that PEs maintain the beneficial properties of DEs, such as diversity and robustness to distribution shift, while achieving comparable accuracy, calibration, and out-of-distribution detection capabilities. The work includes implementation details, experimental results on CIFAR-10/100 and ImageNet datasets and comparisons with existing approaches. It concludes with insights on the reproducibility of results and the potential ethical considerations of deploying such models in safety-critical systems.&#xD;&#xA;&lt;div style=&#34;text-align:center;&#34;&gt;&#xD;&#xA;&lt;h1&gt;Presentation of the model&lt;/h1&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Packed-Ensembles&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Framework to Learn with Interpretation</title>
      <link>http://localhost:1313/posts/a-framework-to-learn-with-interpretation/</link>
      <title>Measuring the Transferability of Pre-trained Models: a link with Neural Collapse Distances on Target Datasets</title>
      <link>http://localhost:1313/posts/transferability/</link>
      <pubDate>Mon, 08 Jan 2024 11:26:03 +0100</pubDate>
      <guid>http://localhost:1313/posts/transferability/</guid>
      <description>&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt; : Marion Chadal and Julie Massé&lt;/p&gt;&#xA;&lt;p&gt;This blog post discusses the paper &amp;ldquo;How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability&amp;rdquo; &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;. It provides an explanation of it so that you can understand the usefulness of measuring transferability, and a reproduction of the authors&amp;rsquo; experiment so that you can better visualize their methodology.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Some additional informations about this course.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Florence d&amp;rsquo;Alché-Buc&lt;/strong&gt; is a full professor at Institut Polytechnique de Paris, Télécom Pari in Statistical Learning. She is the holder of the &amp;ldquo;Data Science and Artificial Intelligence for Digitalized Industry and Services&amp;rdquo; chair at Télécom Paris, and is mainly interested in learning from &lt;em&gt;complex&lt;/em&gt; data, in particular the supervised prediction of graphs, functions and spatio-temporal signals, exploiting the structure and geometry of these objects in regularization and cost functions. More recently, she has been working on the interpretability and robustness of predictive models. &lt;a href=&#34;https://perso.telecom-paristech.fr/fdalche/&#34;&gt;Link to personal webpage&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Articles</title>
      <link>http://localhost:1313/articles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/</guid>
      <description>&lt;p&gt;Hereafter you can find the list of articles proposed for this class and the link to the pdfs.&lt;/p&gt;&#xA;&lt;p&gt;Please add your name in the following &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1raZrD6JZQzjE0wmJbP4iM5-4yt9rAkJIFOqgj1q-JxU/edit?usp=sharing&#34;&gt;file&lt;/a&gt; to pick an article and enter your &lt;strong&gt;github username&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note 1&lt;/strong&gt;: this work can be done in teams (&lt;span style=&#34;text-decoration:underline&#34;&gt;maximum 3 students&lt;/span&gt;).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note 2&lt;/strong&gt;: an article can only be chosen by &lt;span style=&#34;text-decoration:underline&#34;&gt;1 team&lt;/span&gt;.&lt;/p&gt;&#xA;&lt;hr/&gt;&#xD;&#xA;&lt;h2 id=&#34;tips-for-latex&#34;&gt;Tips for Latex&lt;/h2&gt;&#xA;&lt;p&gt;To activate latex writting you need to add this snippet of code (at the end or begining of the post)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tutorial</title>
      <link>http://localhost:1313/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/tutorial/</guid>
      <description>&lt;p&gt;How to create and publish your blogpost ?&lt;/p&gt;&#xA;&lt;hr/&gt;&#xD;&#xA;&lt;p&gt;The blogpost builds upon &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;Markdown&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;For markdown you can easily find a cheat sheet &lt;a href=&#34;https://www.markdownguide.org/cheat-sheet/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;ol start=&#34;0&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Setup: you need to have a GitHub Account, a terminal and a text editor of your choice (e.g.VSCode, nano, gedit)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Install Hugo on your laptop. Hugo is available for all operating systems. You can find the installation guide &lt;a href=&#34;https://gohugo.io/installation/&#34;&gt;here&lt;/a&gt;. Be careful, you need at least Hugo version 0.120 otherwise, this will not work!&#xA;To verify your version&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
